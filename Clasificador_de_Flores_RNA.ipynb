{"cells":[{"cell_type":"markdown","metadata":{"id":"760JrGPqdC3Y"},"source":["üìå Instala las librer√≠as necesarias:\n","\n","1.   TensorFlow y Keras: para crear redes neuronales.\n","2.   scikit-learn (sklearn): para manejar el dataset, dividir los datos y normalizar.\n","3.   pandas: para manejo de datos (aunque no se usa expl√≠citamente en este notebook).\n","\n","\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HcGiNWZU9Cqf"},"outputs":[],"source":["#instalacion de librerias\n","\n","!pip install tensorflow\n","!pip install keras\n","!pip install sklearn\n","!pip install pandas\n"]},{"cell_type":"markdown","metadata":{"id":"aaBgllM8deN3"},"source":["üìå Importaci√≥n de herramientas:\n","\n","0.   load_iris(): carga el famoso dataset de flores.\n","1.   StandardScaler(): normaliza los datos.\n","2.   Sequential y Dense: crean el modelo de red neuronal.\n","3.   to_categorical: convierte etiquetas a vectores (one-hot encoding).\n","\n","\n","\n","\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cOu0oa-v8ogU"},"outputs":[],"source":["# Importamos las librer√≠as necesarias\n","from sklearn.datasets import load_iris          # Cargamos el dataset de flores iris\n","from sklearn.model_selection import train_test_split  # Para dividir en entrenamiento y prueba\n","from sklearn.preprocessing import StandardScaler      # Para escalar (normalizar) los datos\n","from tensorflow.keras.models import Sequential        # Para crear el modelo secuencial (de capas)\n","from tensorflow.keras.layers import Dense             # Para agregar capas densas (conectadas)\n","from tensorflow.keras.utils import to_categorical     # Para convertir las etiquetas a formato one-hot\n","\n","# 1. Cargar el dataset Iris\n","iris = load_iris()\n","X = iris.data                # Las caracter√≠sticas (longitudes de p√©talos, s√©palos, etc.)\n","y = iris.target              # Las etiquetas (0, 1, 2) = setosa, versicolor, virginica\n","\n","# 2. Normalizar los datos (muy importante para redes neuronales)\n","scaler = StandardScaler()\n","X = scaler.fit_transform(X)  # Ajusta y transforma los datos para que tengan media = 0 y varianza = 1\n","\n","# 3. Convertir etiquetas en formato \"one-hot\"\n","# Por ejemplo: 0 -> [1, 0, 0], 1 -> [0, 1, 0], etc.\n","y_cat = to_categorical(y)\n","\n","# 4. Dividir el conjunto en entrenamiento (70%) y prueba (30%)\n","X_train, X_test, y_train, y_test = train_test_split(X, y_cat, test_size=0.3, random_state=42)\n","\n","# 5. Crear el modelo de red neuronal\n","modelo = Sequential()                           # Creamos el modelo secuencial (una capa tras otra)\n","modelo.add(Dense(5, input_shape=(4,), activation='relu'))   # Capa oculta con 5 neuronas y ReLU\n","modelo.add(Dense(3, activation='softmax'))      # Capa de salida con 3 neuronas (una por clase)\n","\n","# 6. Compilar el modelo\n","modelo.compile(\n","    optimizer='adam',                          # Algoritmo de optimizaci√≥n\n","    loss='categorical_crossentropy',           # Funci√≥n de p√©rdida para clasificaci√≥n multiclase\n","    metrics=['accuracy']                       # M√©trica a evaluar: precisi√≥n\n",")\n","\n","# ---------------------------------------------------------------\n","# üîπ Entrenamiento del modelo\n","# ---------------------------------------------------------------\n","\n","modelo.fit(\n","    X_train,        # Datos de entrada para entrenamiento\n","    y_train,        # Etiquetas/valores esperados correspondientes a X_train\n","    epochs=50,      # N√∫mero de veces que el modelo recorrer√° todo el conjunto de entrenamiento\n","    batch_size=5,   # Cantidad de muestras que se procesan antes de actualizar los pesos del modelo\n","    verbose=1       # Nivel de detalle en la salida de entrenamiento:\n","                    #   0 ‚Üí sin informaci√≥n\n","                    #   1 ‚Üí barra de progreso por epoch (detallado)\n","                    #   2 ‚Üí solo m√©tricas por epoch\n",")\n","\n","\n","# 8. Evaluar el modelo con los datos de prueba\n","loss, accuracy = modelo.evaluate(X_test, y_test)\n","print(f\"\\nPrecisi√≥n en el conjunto de prueba: {accuracy:.2f}\")\n","\n","# 9. Probar el modelo con una nueva flor\n","# Setosa\n","nueva_flor = [[5.1, 3.5, 1.4, 0.2]]       # Medidas de una flor iris\n","# Versicolor\n","#nueva_flor = [[6.0, 2.2, 4.0, 1.0]]\n","# Virginica\n","#nueva_flor = [[6.3, 3.3, 6.0, 2.5]]\n","#Escalamiento\n","nueva_flor = scaler.transform(nueva_flor)  # Normalizamos igual que antes\n","prediccion = modelo.predict(nueva_flor)    # Obtenemos las probabilidades\n","print(\"\\nProbabilidades por clase (softmax):\", prediccion[0])\n","print(\"Clase predicha:\", iris.target_names[prediccion.argmax()])\n"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.4"}},"nbformat":4,"nbformat_minor":0}