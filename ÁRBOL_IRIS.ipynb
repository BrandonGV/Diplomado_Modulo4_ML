{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Importar librerías\n","\n"],"metadata":{"id":"-bWEsxjfR9RR"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"rtxsQyGSRChr"},"outputs":[],"source":["#Conjunto de datos\n","from sklearn.datasets import load_iris\n","#Árbol de decisión\n","from sklearn import tree\n","#Análisis\n","import pandas as pd\n","#Segmentación de datos (entrenamiento, validación y prueba)\n","from sklearn.model_selection import train_test_split\n","#Vizualización\n","import seaborn as sns #Box plot\n","import matplotlib.pyplot as plt #Distribución\n","#Importamos la función confusion_matrix desde sklearn.metrics\n","from sklearn.metrics import confusion_matrix\n","#Libreria para metricas\n","from sklearn.metrics import accuracy_score"]},{"cell_type":"markdown","source":["# Carga de conjunto de datos"],"metadata":{"id":"qR2nNml3SGX3"}},{"cell_type":"code","source":["#Dataset\n","iris = load_iris()\n","#Dataframe\n","df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n","#Ver información de una dataset\n","df.info()\n","#Etiqueta de salida (setosa, versicolor y virginica)\n","df['target'] = iris.target\n","#Adición de nombres a etiquetas de salida\n","df['species'] = df['target'].map(dict(enumerate(iris.target_names)))"],"metadata":{"id":"iHAwUs2DSFfo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Mostrar las primeras filas del DataFrame completo\n","print(df.head(10))"],"metadata":{"id":"zKfKa1mF2VZG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Estadística datos"],"metadata":{"id":"T7ADakOKVJVI"}},{"cell_type":"code","source":["# Estadísticas descriptivas\n","print(df.describe())"],"metadata":{"id":"-IJN98qWVRCO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Vizualización de distribución"],"metadata":{"id":"GcdyTofrXNhm"}},{"cell_type":"code","source":["# Establece el tamaño de la figura (ancho x alto en pulgadas)\n","plt.figure(figsize=(8, 6))\n","\n","# Crea un gráfico de dispersión con seaborn\n","# - data: el DataFrame que contiene los datos\n","# - x: columna para el eje X ('largo del sépalo')\n","# - y: columna para el eje Y ('ancho del sépalo')\n","# - hue: color según la especie (distingue clases con diferentes colores)\n","# - palette: paleta de colores ('Set2' es una paleta pastel atractiva)\n","# - s: tamaño de los puntos en el gráfico\n","sns.scatterplot(data=df,\n","                x='sepal length (cm)',\n","                y='sepal width (cm)',\n","                hue='species',\n","                palette='Set2',\n","                s=100)\n","\n","# Título del gráfico\n","plt.title(\"Gráfico de Dispersión: Largo vs Ancho del Sépalo\")\n","# Etiqueta del eje X\n","plt.xlabel(\"Largo del Sépalo (cm)\")\n","# Etiqueta del eje Y\n","plt.ylabel(\"Ancho del Sépalo (cm)\")\n","# Activa la grilla para facilitar la lectura del gráfico\n","plt.grid(True)\n","# Muestra el gráfico en pantalla\n","plt.show()\n"],"metadata":{"id":"8M0iu24-XRpu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Vizualización Box plot"],"metadata":{"id":"uJrjGZcvWq24"}},{"cell_type":"code","source":["# Creamos una figura general con un tamaño de 14x10 pulgadas\n","plt.figure(figsize=(14, 10))\n","\n","# Recorremos cada característica numérica del conjunto de datos 'iris'\n","for i, column in enumerate(iris.feature_names):\n","\n","    # Creamos una subgráfica en una cuadrícula de 2 filas x 2 columnas\n","    # 'i+1' indica la posición actual (1 a 4)\n","    plt.subplot(2, 2, i+1)\n","\n","    # Dibujamos un boxplot con seaborn\n","    # En el eje X colocamos las especies (setosa, versicolor, virginica)\n","    # En el eje Y colocamos la característica numérica actual (ej. sepal length)\n","    # 'data=df' indica que los datos vienen del DataFrame 'df'\n","    sns.boxplot(x='species', y=column, data=df)\n","\n","    # Añadimos un título a cada subgráfico con el nombre de la característica\n","    plt.title(f'Distribución de {column}')\n","\n","# Ajustamos el diseño para que los subgráficos no se superpongan\n","plt.tight_layout()\n","\n","# Mostramos todos los gráficos en pantalla\n","plt.show()\n"],"metadata":{"id":"YVqDOXg3WxDG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Segmentación de datos 70%, 15%, 15%"],"metadata":{"id":"gN3m8kjjaBSf"}},{"cell_type":"code","source":["# División inicial en 70% entrenamiento y 30% temporal\n","X = df[iris.feature_names]\n","y = df['target']\n","#Datos de entrenamiento 70%\n","X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.30, random_state=42, stratify=y)\n","\n","# División del 30% restante en validación y prueba (50/50 => 15% cada uno)\n","X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.50, random_state=42, stratify=y_temp)\n","\n","print(f\"Entrenamiento: {len(X_train)}, Validación: {len(X_val)}, Prueba: {len(X_test)}\")\n"],"metadata":{"id":"3514fT9SaA4n"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Carga de modelo y entrenamiento"],"metadata":{"id":"IW8ixdl-Smkv"}},{"cell_type":"code","source":["# -------------------------------\n","#     🔁 DEFINICIÓN DEL MODELO\n","# -------------------------------\n","\n","# Creamos un modelo de árbol de decisión para clasificación\n","# El parámetro 'random_state=42' se usa para fijar un generador\n","# de valores aleatorios\n","\n","modelo = tree.DecisionTreeClassifier(random_state=42)\n","\n","# -------------------------------\n","#         🔧 ENTRENAMIENTO\n","# -------------------------------\n","\n","# Entrenamos (ajustamos) el modelo usando los datos de entrenamiento 70%\n","# X_train: conjunto de variables independientes (características)\n","# y_train: conjunto de variables dependientes (clase o etiqueta)\n","modelo.fit(X_train, y_train)"],"metadata":{"id":"VSO1StT3Skmx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ------------------------------------\n","#     🌳 VISUALIZACIÓN DEL ÁRBOL\n","# ------------------------------------\n","\n","# Usamos la función plot_tree de sklearn para dibujar el árbol de decisión entrenado\n","# Esto muestra gráficamente cómo el modelo toma decisiones (las divisiones en los nodos)\n","# Es útil para interpretar el modelo y entender qué atributos está utilizando\n","tree.plot_tree(modelo)\n"],"metadata":{"id":"Suxm_lWxROS3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ---------------------------------------------\n","#   🔮 PREDICCIÓN SOBRE LOS DATOS DE VALIDACIÓN\n","# ---------------------------------------------\n","\n","# Utilizamos el modelo ya entrenado para hacer predicciones sobre el conjunto de validación (X_val)\n","# Esto permite evaluar el rendimiento del modelo en datos que no se usaron en el entrenamiento\n","# y_pred_val almacenará las clases predichas por el modelo para X_val\n","y_pred_val = modelo.predict(X_val)"],"metadata":{"id":"eEMI0l6gcUgv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ------------------------------------\n","# 📏 MÉTRICAS DE EVALUACIÓN DEL MODELO\n","# ------------------------------------\n","# 🔹 Accuracy: porcentaje total de aciertos\n","# 2. Accuracy de validacion\n","accuracy_v = accuracy_score(y_val, y_pred_val)\n","# Imprimimos las métricas %\n","print(\"Accuracy:\", accuracy_v * 100)"],"metadata":{"id":"-8H4PUFl633a"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ---------------------------------------\n","#     🔮 PREDICCIÓN CON EL MODELO\n","# ---------------------------------------\n","\n","# Usamos el modelo ya entrenado para hacer predicciones sobre los datos de prueba (X_test)\n","# El resultado (y_pred) será un array con las clases predichas para cada observación de prueba\n","y_pred = modelo.predict(X_test)"],"metadata":{"id":"VKTc1HDQbWv2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ------------------------------------\n","# 📏 MÉTRICAS DE EVALUACIÓN DEL MODELO\n","# ------------------------------------\n","# 1. Accuracy de prueba\n","# 🔹 Accuracy: porcentaje total de aciertos\n","accuracy_p = accuracy_score(y_test, y_pred)\n","# Imprimimos las métricas %\n","print(\"Accuracy:\", accuracy_p * 100)\n"],"metadata":{"id":"rE0wdPARLioA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Vizualización de información"],"metadata":{"id":"RKQorOKwSPah"}},{"cell_type":"code","source":["# ------------------------------------\n","#       📊 MATRIZ DE CONFUSIÓN\n","# ------------------------------------\n","\n","# Calculamos la matriz de confusión comparando los valores reales (y_test)\n","# con las predicciones hechas por el modelo (y_pred)\n","# La matriz indica cuántas predicciones fueron correctas y cuántas se equivocaron\n","cm = confusion_matrix(y_test, y_pred)\n","\n","# --------------------------------------------\n","#      📈 GRÁFICO DE LA MATRIZ DE CONFUSIÓN\n","# --------------------------------------------\n","\n","# Usamos seaborn para crear un mapa de calor (heatmap) de la matriz\n","# 'annot=True' muestra los números en cada celda\n","# 'fmt=\"d\"' indica que los valores son enteros\n","# 'cmap=\"Blues\"' da el color azul al gráfico\n","sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n","\n","# Etiquetas de los ejes\n","plt.xlabel(\"Predicción\")    # Eje X: lo que predijo el modelo\n","plt.ylabel(\"Verdadero\")     # Eje Y: las clases reales\n","plt.title(\"Matriz de Confusión\")  # Título del gráfico\n","\n","# Muestra el gráfico en pantalla\n","plt.show()"],"metadata":{"id":"rZ9JFuOnbfRG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Exportar modelo ML"],"metadata":{"id":"T4h9F4lzjdY1"}},{"cell_type":"code","source":["#Exportar modelo de machine learning\n","import joblib # joblib sirve para serializar eficientemente objetos Python,\n","               # en especial modelos de machine learning, permitiendo guardarlos\n","               # y cargarlos más rápido, lo cual es útil para la persistencia.\n","\n","joblib.dump(modelo, 'modelo_iris.pkl')\n","# Esta línea utiliza la función 'dump' de joblib para guardar (serializar) el\n","# objeto Python llamado 'modelo' (que se asume es un modelo de Machine Learning\n","# previamente entrenado, como un clasificador de Scikit-learn) en un archivo\n","# binario llamado 'modelo_iris.pkl'. Esto permite reutilizar el modelo sin tener\n","# que entrenarlo de nuevo.\n"],"metadata":{"id":"Yv9W_DNljcpe"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Cargar modelo ML\n"],"metadata":{"id":"B06yjV5Fk0l8"}},{"cell_type":"code","source":["# Nombre del archivo donde se guardó el modelo\n","nombre_archivo = 'modelo_iris.pkl'\n","\n","# Cargar el modelo desde el archivo binario\n","# El modelo cargado se asigna a la variable 'modelo_cargado'\n","modelo_cargado = joblib.load(nombre_archivo)\n","\n","print(f\"✅ Modelo cargado exitosamente desde '{nombre_archivo}'.\")\n"],"metadata":{"id":"8d0bss7Wk0Ml"},"execution_count":null,"outputs":[]}]}