{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# ===============================================\n","# üìå 1. Importaci√≥n de librer√≠as necesarias\n","# ==============================================="],"metadata":{"id":"m-yBQSsTTjBm"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"mHQOjokITfw6"},"outputs":[],"source":["# ---------------------------------------------------------------\n","# üì¶ Importar librer√≠as para manejo y an√°lisis de datos\n","# ---------------------------------------------------------------\n","\n","import pandas as pd   # Pandas: se usa para manipular, limpiar y analizar datos estructurados (tablas tipo Excel o CSV)\n","import numpy as np    # NumPy: se usa para operaciones num√©ricas y manejo de arreglos multidimensionales\n","\n","# ---------------------------------------------------------------\n","# üìä Librer√≠as para visualizaci√≥n (gr√°ficos)\n","# ---------------------------------------------------------------\n","\n","import matplotlib.pyplot as plt   # Matplotlib: permite crear gr√°ficos b√°sicos (l√≠neas, barras, dispersi√≥n, etc.)\n","import seaborn as sns             # Seaborn: librer√≠a construida sobre Matplotlib que crea gr√°ficos estad√≠sticos m√°s atractivos y con menos c√≥digo\n","\n","# ---------------------------------------------------------------\n","# ü§ñ Librer√≠as de Machine Learning (scikit-learn)\n","# ---------------------------------------------------------------\n","\n","from sklearn.cluster import KMeans               # Algoritmo de agrupamiento (clustering) no supervisado, agrupa datos en K grupos\n","from sklearn.model_selection import train_test_split  # Divide los datos en conjuntos de entrenamiento y prueba\n","from sklearn.preprocessing import StandardScaler      # Escala los datos para que todas las variables tengan media 0 y desviaci√≥n est√°ndar 1\n","from sklearn.metrics import silhouette_score          # Mide qu√© tan bien definidos est√°n los clusters (calidad del agrupamiento)\n","from sklearn.decomposition import PCA                 # An√°lisis de Componentes Principales: reduce la dimensionalidad de los datos para visualizaci√≥n o simplificaci√≥n\n","\n","# ---------------------------------------------------------------\n","# üé® Configurar el estilo de los gr√°ficos\n","# ---------------------------------------------------------------\n","sns.set(style=\"whitegrid\")   # Define un estilo visual limpio con fondo blanco y l√≠neas de cuadr√≠cula (ideal para an√°lisis de datos)\n","\n","# ---------------------------------------------------------------\n","# üé≤ Fijar semilla aleatoria\n","# ---------------------------------------------------------------\n","np.random.seed(42)\n","# Establece una semilla para el generador de n√∫meros aleatorios de NumPy.\n","# Esto garantiza que los resultados (por ejemplo, los grupos del KMeans o muestras aleatorias)\n","# sean reproducibles: si ejecutas el c√≥digo otra vez, obtendr√°s el mismo resultado.\n","\n","# ---------------------------------------------------------------\n","# ‚úÖ Confirmaci√≥n de carga correcta\n","# ---------------------------------------------------------------\n","print(\"‚úÖ Librer√≠as importadas correctamente.\")\n","# Imprime un mensaje indicando que todas las librer√≠as se importaron sin errores.\n"]},{"cell_type":"markdown","source":["# ===============================================\n","# üìå 2. Carga del dataset\n","# ==============================================="],"metadata":{"id":"avP8GSwUTxy_"}},{"cell_type":"code","source":["# Usamos el dataset \"Mall Customers\" con datos de clientes\n","# Puedes subir el archivo a Colab con el bot√≥n \"Subir archivo\"\n","from google.colab import files\n","uploaded = files.upload()"],"metadata":{"id":"oMPgAC7pTy31"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["üìã Columnas del dataset\n","\n","| Columna                  | Tipo       | Descripci√≥n                                                                              |\n","| ------------------------ | ---------- | ---------------------------------------------------------------------------------------- |\n","| `CustomerID`             | Num√©rica   | Identificador √∫nico del cliente (solo sirve como referencia, no para an√°lisis).          |\n","| `Gender`                 | Categ√≥rica | G√©nero del cliente: `\"Male\"` o `\"Female\"`.                                               |\n","| `Age`                    | Num√©rica   | Edad del cliente, en a√±os.                                                               |\n","| `Annual Income (k$)`     | Num√©rica   | Ingreso anual estimado del cliente, en miles de d√≥lares (por ejemplo, 60 = \\$60,000).    |\n","| `Spending Score (1-100)` | Num√©rica   | Puntuaci√≥n otorgada por el sistema del mall, basada en los h√°bitos de gasto del cliente. |\n"],"metadata":{"id":"ZNiFpfpAUYmX"}},{"cell_type":"code","source":["# Leer el archivo CSV subido\n","df = pd.read_csv(\"Mall_Customers.csv\")\n","df.head() #Muestra las 5 priemras columnas del dataset"],"metadata":{"id":"8guKHJIWT3e1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# ===============================================\n","# üìå 3. An√°lisis exploratorio inicial\n","# ==============================================="],"metadata":{"id":"ssDQl506U0oO"}},{"cell_type":"code","source":["# Informaci√≥n general del DataFrame\n","print(\"\\nInformaci√≥n general del DataFrame:\")\n","print(df.info())"],"metadata":{"id":"R1kVZM2wU2rd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Estad√≠sticas descriptivas\n","print(\"\\nEstad√≠sticas descriptivas:\")\n","print(df.describe())"],"metadata":{"id":"EliM12w_U6Ol"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Conteo de valores √∫nicos en columnas categ√≥ricas (si las hay)\n","print(\"\\nConteo de valores √∫nicos en 'Gender':\")\n","print(df['Genre'].value_counts())"],"metadata":{"id":"3nHNDHNMcI2h"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ---------------------------------------------------------------\n","# üìä Visualizar relaciones entre variables num√©ricas con Seaborn\n","# ---------------------------------------------------------------\n","\n","sns.pairplot(df[['Age', 'Annual Income (k$)', 'Spending Score (1-100)']])\n","# sns.pairplot() crea una matriz de gr√°ficos de dispersi√≥n (scatterplots) entre todas las combinaciones\n","# posibles de las variables num√©ricas seleccionadas.\n","# Cada gr√°fico muestra c√≥mo se relaciona una variable con otra.\n","# En la diagonal principal se muestran histogramas o distribuciones de cada variable individualmente.\n","\n","# Par√°metros:\n","# df[['Age', 'Annual Income (k$)', 'Spending Score (1-100)']]\n","# ‚Üí selecciona del DataFrame `df` solo las tres columnas indicadas:\n","#   - 'Age' ‚Üí edad de los clientes\n","#   - 'Annual Income (k$)' ‚Üí ingreso anual en miles de d√≥lares\n","#   - 'Spending Score (1-100)' ‚Üí puntaje de gasto (nivel de consumo del cliente)\n","# Estas variables son num√©ricas y se usar√°n para analizar correlaciones visuales.\n","\n","plt.suptitle('Distribuciones y relaciones entre variables', y=1.02)\n","# plt.suptitle() agrega un t√≠tulo general a toda la figura (no a cada subgr√°fico).\n","# 'y=1.02' eleva el t√≠tulo un poco por encima del gr√°fico para evitar que se superponga con los subgr√°ficos.\n","\n","plt.show()\n","# plt.show() muestra la figura generada en pantalla.\n","# Es necesario para visualizar los gr√°ficos en la mayor√≠a de entornos (como scripts de Python o notebooks).\n"],"metadata":{"id":"0trRLCwMU9_V"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ---------------------------------------------------------------\n","# üìä Visualizaci√≥n de la distribuci√≥n de las variables clave\n","# ---------------------------------------------------------------\n","\n","plt.figure(figsize=(15, 5))\n","# Crea una nueva figura con un tama√±o de 15 pulgadas de ancho por 5 de alto.\n","# Esto permite que los tres gr√°ficos (subplots) que haremos se vean grandes y no amontonados.\n","\n","# ---------------------------------------------------------------\n","# üßì Subgr√°fico 1: Distribuci√≥n de la edad\n","# ---------------------------------------------------------------\n","plt.subplot(1, 3, 1)\n","# Crea el primer subgr√°fico dentro de una cuadr√≠cula de 1 fila y 3 columnas.\n","# El n√∫mero 1 indica que este ser√° el primer gr√°fico (de izquierda a derecha).\n","\n","sns.histplot(df['Age'], kde=True)\n","# Dibuja un histograma de la columna \"Age\" del DataFrame `df`.\n","# Un histograma muestra la frecuencia (cu√°ntas veces ocurre) de distintos rangos de edad.\n","# El par√°metro `kde=True` agrega una l√≠nea de densidad suavizada (Kernel Density Estimation),\n","# que muestra una curva continua para visualizar la forma general de la distribuci√≥n.\n","\n","plt.title('Distribuci√≥n de Edad')\n","# Agrega un t√≠tulo al primer subgr√°fico.\n","\n","# ---------------------------------------------------------------\n","# üí∞ Subgr√°fico 2: Distribuci√≥n del ingreso anual\n","# ---------------------------------------------------------------\n","plt.subplot(1, 3, 2)\n","# Crea el segundo subgr√°fico en la misma figura (posici√≥n 2 de 3).\n","\n","sns.histplot(df['Annual Income (k$)'], kde=True)\n","# Dibuja un histograma de la variable \"Annual Income (k$)\" (ingreso anual en miles de d√≥lares).\n","# Permite observar si los ingresos est√°n concentrados en ciertos rangos (por ejemplo, ingresos bajos o altos).\n","\n","plt.title('Distribuci√≥n de Ingresos Anuales (k$)')\n","# Agrega t√≠tulo descriptivo a este subgr√°fico.\n","\n","# ---------------------------------------------------------------\n","# üí≥ Subgr√°fico 3: Distribuci√≥n del puntaje de gasto\n","# ---------------------------------------------------------------\n","plt.subplot(1, 3, 3)\n","# Crea el tercer subgr√°fico de la figura.\n","\n","sns.histplot(df['Spending Score (1-100)'], kde=True)\n","# Dibuja un histograma de la variable \"Spending Score (1-100)\".\n","# Esta variable suele representar el comportamiento de compra o gasto de los clientes.\n","# El KDE muestra si hay grupos de clientes que gastan poco, medio o mucho.\n","\n","plt.title('Distribuci√≥n de Puntuaci√≥n de Gasto')\n","# Agrega t√≠tulo al tercer gr√°fico.\n","\n","# ---------------------------------------------------------------\n","# üß© Ajustes finales del dise√±o\n","# ---------------------------------------------------------------\n","plt.tight_layout()\n","# Ajusta autom√°ticamente los m√°rgenes y espacios entre subgr√°ficos para evitar que los textos o t√≠tulos se sobrepongan.\n","\n","plt.show()\n","# Muestra la figura con los tres histogramas.\n","\n","# ---------------------------------------------------------------\n","# ‚úÖ Mensaje de confirmaci√≥n\n","# ---------------------------------------------------------------\n","print(\"‚úÖ An√°lisis exploratorio de datos completado.\")\n","# Muestra un mensaje en consola indicando que la visualizaci√≥n y an√°lisis se realizaron correctamente.\n"],"metadata":{"id":"9H30-RjjcN65"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# ===============================================\n","# üìå 4. Limpieza de datos\n","# ==============================================="],"metadata":{"id":"KROfwTrLVGze"}},{"cell_type":"code","source":["# Verificamos valores nulos\n","print(df.isnull().sum())"],"metadata":{"id":"TeY23lF5VIZd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Eliminamos la columna 'CustomerID' ya que no aporta al an√°lisis\n","df_clean = df.drop(['CustomerID'], axis=1)"],"metadata":{"id":"2U3bk6C8VMYc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ---------------------------------------------------------------\n","# üî¢ Conversi√≥n de variable categ√≥rica 'Gender' a variable num√©rica\n","# ---------------------------------------------------------------\n","\n","df_clean = pd.get_dummies(df_clean, drop_first=True)\n","# Esta funci√≥n convierte autom√°ticamente las variables categ√≥ricas (de texto) del DataFrame `df_clean`\n","# en variables num√©ricas mediante el m√©todo \"One-Hot Encoding\".\n","#\n","# üëâ One-Hot Encoding:\n","#    - Toma una columna con categor√≠as de texto (por ejemplo, 'Gender' con valores 'Male' y 'Female')\n","#    - Crea una nueva columna binaria (de 0s y 1s) para cada categor√≠a.\n","#\n","# Ejemplo:\n","#    Si tenemos:\n","#       Gender\n","#       -------\n","#       Male\n","#       Female\n","#       Male\n","#\n","#    Al aplicar pd.get_dummies(df_clean), se obtiene:\n","#       Gender_Female   Gender_Male\n","#       --------------  -----------\n","#       0               1\n","#       1               0\n","#       0               1\n","#\n","# ‚öôÔ∏è Par√°metro:\n","#    - drop_first=True ‚Üí elimina la primera categor√≠a (por ejemplo, 'Gender_Male')\n","#      para evitar la *trampa de la multicolinealidad* (cuando una variable puede\n","#      deducirse de las otras, lo que causa problemas en modelos lineales).\n","#\n","# Resultado:\n","#    - El DataFrame `df_clean` ahora solo contiene valores num√©ricos,\n","#      listos para usarse en modelos de Machine Learning.\n"],"metadata":{"id":"vq-2hCERVQF0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Resultado\n","df_clean.head()"],"metadata":{"id":"c8dhg4D7VSaF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# ===============================================\n","# üìå 5. Normalizaci√≥n de los datos\n","# ==============================================="],"metadata":{"id":"_wlktHzQVdH_"}},{"cell_type":"markdown","source":["üîÑ **¬øPor qu√© normalizamos los datos?**\n","\n","K-means calcula distancias entre puntos. Si usamos valores sin escalar (ej. edad vs ingresos), una variable dominar√° la otra.  \n","La normalizaci√≥n pone todos los valores en la **misma escala (media=0, desviaci√≥n est√°ndar=1)** para que todas las variables tengan el mismo peso en la segmentaci√≥n.\n"],"metadata":{"id":"jjWp8rjTlolp"}},{"cell_type":"code","source":["# ---------------------------------------------------------------\n","# ‚öñÔ∏è Estandarizaci√≥n de las variables num√©ricas\n","# ---------------------------------------------------------------\n","\n","scaler = StandardScaler()\n","# Crea un objeto de la clase StandardScaler del m√≥dulo sklearn.preprocessing.\n","# Este objeto se encargar√° de escalar (normalizar) las variables num√©ricas del DataFrame.\n","#\n","# ¬øPor qu√© escalar?\n","# En muchos algoritmos de Machine Learning (como K-Means, Regresi√≥n Log√≠stica o PCA),\n","# las variables con valores m√°s grandes pueden \"dominar\" las dem√°s.\n","# Por ejemplo, si una variable mide ingresos en miles y otra edad en a√±os,\n","# el ingreso tiene una escala mucho mayor y puede sesgar el resultado.\n","#\n","# La estandarizaci√≥n convierte todas las variables para que:\n","#   - Tengan media (promedio) = 0\n","#   - Tengan desviaci√≥n est√°ndar = 1\n","#\n","# F√≥rmula:\n","#   X_esc = (X - media) / desviaci√≥n_est√°ndar\n","\n","df_scaled = scaler.fit_transform(df_clean)\n","# Aplica la estandarizaci√≥n a todas las columnas num√©ricas del DataFrame `df_clean`.\n","# - fit() calcula la media y desviaci√≥n est√°ndar de cada variable.\n","# - transform() aplica la transformaci√≥n a los datos.\n","# - fit_transform() combina ambos pasos en uno solo.\n","#\n","# El resultado `df_scaled` es un arreglo NumPy (no un DataFrame) con los valores escalados.\n","# Cada columna tiene media 0 y desviaci√≥n est√°ndar 1.\n","\n","# ---------------------------------------------------------------\n","# üîç Verificaci√≥n de la transformaci√≥n\n","# ---------------------------------------------------------------\n","\n","print(\"Media:\", df_scaled.mean(axis=0))\n","# Calcula y muestra la media de los valores escalados (por columnas).\n","# Deber√≠a ser aproximadamente 0 para cada variable, si la estandarizaci√≥n fue correcta.\n","\n","print(\"Desviaci√≥n est√°ndar:\", df_scaled.std(axis=0))\n","# Calcula y muestra la desviaci√≥n est√°ndar de los valores escalados (por columnas).\n","# Deber√≠a ser aproximadamente 1 para todas las variables.\n"],"metadata":{"id":"EiFMZqsgVe_-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["‚úÖ Media ~ 0\n","La media de cada columna (variable) ha sido transformada para que sea pr√°cticamente cero.\n","Esos valores muy peque√±os como -1e-16 o 3e-17 son num√©ricamente cercanos a cero, con peque√±as diferencias por redondeo y precisi√≥n num√©rica en coma flotante.\n","\n","üîπ Ejemplo: -1.02140518e-16 ‚âà 0\n","\n","‚úÖ Desviaci√≥n est√°ndar = 1\n","Cada variable ahora tiene varianza 1, es decir, han sido \"normalizadas\" para tener la misma escala de dispersi√≥n."],"metadata":{"id":"aH4pqS7DcrZR"}},{"cell_type":"code","source":["# ---------------------------------------------------------------\n","# üîÑ Convertir el array escalado nuevamente a un DataFrame\n","# ---------------------------------------------------------------\n","\n","df_scaled = pd.DataFrame(df_scaled, columns=df_clean.columns)\n","# La funci√≥n pd.DataFrame() convierte el arreglo NumPy `df_scaled` (resultado de StandardScaler)\n","# en un DataFrame de pandas.\n","#\n","# Par√°metros:\n","#   - df_scaled ‚Üí los valores num√©ricos ya estandarizados (media = 0, desviaci√≥n est√°ndar = 1)\n","#   - columns=df_clean.columns ‚Üí usa los mismos nombres de columnas que ten√≠a el DataFrame original `df_clean`\n","#\n","# Resultado:\n","#   - Ahora `df_scaled` es un DataFrame de pandas con los mismos nombres de variables,\n","#     pero con valores escalados.\n","\n","# ---------------------------------------------------------------\n","# üéØ Selecci√≥n de las variables num√©ricas principales\n","# ---------------------------------------------------------------\n","\n","df_scaled = pd.DataFrame(df_scaled[['Age', 'Annual Income (k$)', 'Spending Score (1-100)']])\n","# De todas las columnas del DataFrame escalado, seleccionamos solo tres:\n","#   - 'Age' ‚Üí edad del cliente\n","#   - 'Annual Income (k$)' ‚Üí ingreso anual en miles de d√≥lares\n","#   - 'Spending Score (1-100)' ‚Üí nivel de gasto o consumo\n","#\n","# Esto se hace porque estas tres variables son las m√°s relevantes para el an√°lisis\n","# y se quieren visualizar en un gr√°fico comparativo.\n","#\n","# Se crea un nuevo DataFrame (tambi√©n llamado df_scaled) solo con esas columnas.\n","\n","# ---------------------------------------------------------------\n","# üìä Visualizaci√≥n: relaciones entre variables normalizadas\n","# ---------------------------------------------------------------\n","\n","sns.pairplot(df_scaled)\n","# Crea una matriz de gr√°ficos (pairplot) que muestra:\n","#   - En la diagonal ‚Üí histogramas o distribuciones de cada variable.\n","#   - Fuera de la diagonal ‚Üí gr√°ficos de dispersi√≥n (scatterplots) entre pares de variables.\n","#\n","# Dado que los datos est√°n normalizados, todas las variables est√°n en la misma escala,\n","# lo que facilita comparar tendencias o correlaciones.\n","\n","plt.suptitle('Distribuciones y relaciones entre variables (normalizados)', y=1.02)\n","# Agrega un t√≠tulo general a todo el conjunto de subgr√°ficos.\n","# El par√°metro 'y=1.02' ajusta la posici√≥n vertical del t√≠tulo (ligeramente por encima de los gr√°ficos).\n","\n","plt.show()\n","# Muestra en pantalla la figura generada con Seaborn y Matplotlib.\n","\n"],"metadata":{"id":"wSPFwwkqh45S"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["üìä 1. Distribuciones individuales (diagonal)\n","Age (Edad): Distribuci√≥n sesgada a la izquierda (m√°s clientes j√≥venes que mayores).\n","\n","Annual Income (Ingresos): Distribuci√≥n m√°s uniforme pero con ligera concentraci√≥n entre -1 y 1.\n","\n","Spending Score: Presenta una distribuci√≥n casi sim√©trica, aunque se observan clientes con puntajes extremos.\n","\n","Todas las variables tienen centro en 0 y rango t√≠pico entre -2 y 2 ‚Üí ‚úÖ Normalizaci√≥n exitosa.\n"],"metadata":{"id":"0QB0zEu8lNdz"}},{"cell_type":"markdown","source":["# ===============================================\n","# üìå 6. Segmentaci√≥n de datos (70% train, 15% val, 15% test)\n","# ==============================================="],"metadata":{"id":"GRR8UaQvVmmP"}},{"cell_type":"code","source":["# Usamos train_test_split para crear subconjuntos de entrenamiento, validaci√≥n y prueba\n","X_train, X_temp = train_test_split(df_scaled, test_size=0.30, random_state=42)\n","X_val, X_test = train_test_split(X_temp, test_size=0.50, random_state=42)\n","\n","print(f'Tama√±o del conjunto de entrenamiento: {len(X_train)}')\n","print(f'Tama√±o del conjunto de validaci√≥n: {len(X_val)}')\n","print(f'Tama√±o del conjunto de prueba: {len(X_test)}')"],"metadata":{"id":"rGINvr3jVk8c"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# ===============================================\n","# üìå 7. Determinar n√∫mero √≥ptimo de clusters (m√©todo del codo)\n","# ==============================================="],"metadata":{"id":"WWaVfTgrV31t"}},{"cell_type":"code","source":["# ---------------------------------------------------------------\n","# üí° M√©todo del codo para elegir el n√∫mero √≥ptimo de clusters (K)\n","# ---------------------------------------------------------------\n","\n","inertia = []\n","# Creamos una lista vac√≠a para almacenar la inercia de cada modelo KMeans.\n","# La inercia mide la suma de las distancias cuadradas de cada punto a su centroide.\n","# Valores m√°s bajos indican clusters m√°s compactos.\n","\n","K = range(1, 11)\n","# Definimos un rango de posibles valores de K (1 a 10 clusters) para probar.\n","# El objetivo es encontrar el \"codo\" en la curva donde agregar m√°s clusters ya no reduce significativamente la inercia.\n","# Inercia (medida de cu√°n compactos est√°n los clusters)\n","\n","# ---------------------------------------------------------------\n","# üîÑ Iteramos sobre los valores de K\n","# ---------------------------------------------------------------\n","for k in K:\n","    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n","    # Creamos un modelo KMeans con:\n","    #   - n_clusters=k ‚Üí n√∫mero de clusters a generar\n","    #   - random_state=42 ‚Üí semilla para resultados reproducibles\n","    #   - n_init=10 ‚Üí n√∫mero de veces que el algoritmo KMeans se inicializa con centroides diferentes;\n","    #     se toma la mejor soluci√≥n (la que minimiza la inercia)\n","\n","    kmeans.fit(X_train)\n","    # Entrenamos el modelo con los datos de entrenamiento `X_train`.\n","    # El algoritmo asigna cada punto a un cluster y ajusta los centroides para minimizar la inercia.\n","\n","    inertia.append(kmeans.inertia_)\n","    # Guardamos el valor de la inercia para este n√∫mero de clusters.\n","    # kmeans.inertia_ es la suma de distancias cuadradas de cada punto a su centroide.\n","\n","# ---------------------------------------------------------------\n","# üìà Visualizaci√≥n del m√©todo del codo\n","# ---------------------------------------------------------------\n","plt.plot(K, inertia, 'bo-')\n","# 'bo-' ‚Üí c√≠rculos azules ('b') conectados por l√≠nea continua ('-')\n","# El eje X representa el n√∫mero de clusters (K)\n","# El eje Y representa la inercia correspondiente a cada K\n","\n","plt.xlabel('N√∫mero de clusters (K)')\n","plt.ylabel('Inercia')\n","plt.title('M√©todo del codo para elegir K')\n","plt.show()\n","# Muestra la gr√°fica en pantalla\n","# El \"codo\" en la curva indica el K √≥ptimo:\n","#   - Antes del codo: agregar clusters reduce mucho la inercia\n","#   - Despu√©s del codo: agregar m√°s clusters apenas mejora la inercia (posible sobreajuste)\n"],"metadata":{"id":"tuXhf5ZbV5wd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# ===============================================\n","# üìå 8. Entrenamiento del modelo K-means\n","# ==============================================="],"metadata":{"id":"qmqW2OjPWH7u"}},{"cell_type":"code","source":["# ---------------------------------------------------------------\n","# üîπ Definir el n√∫mero √≥ptimo de clusters\n","# ---------------------------------------------------------------\n","\n","# Suponemos que el mejor K, determinado visualmente con el m√©todo del codo, es 5\n","# En este caso, se est√° usando 4 como ejemplo:\n","k_optimo = 4\n","# k_optimo ‚Üí n√∫mero de clusters que vamos a usar para entrenar el modelo KMeans.\n","# Este valor se suele elegir observando la gr√°fica del codo.\n","\n","# ---------------------------------------------------------------\n","# üîπ Entrenar el modelo KMeans\n","# ---------------------------------------------------------------\n","\n","kmeans = KMeans(\n","    n_clusters=k_optimo,   # N√∫mero de clusters a crear\n","    random_state=42,       # Semilla aleatoria para reproducibilidad\n","    n_init=10              # N√∫mero de inicializaciones diferentes para evitar m√≠nimos locales\n",")\n","kmeans.fit(X_train)\n","# Ajusta el modelo KMeans a los datos de entrenamiento `X_train`.\n","# El algoritmo encuentra los centroides de los clusters y asigna cada punto al cluster m√°s cercano.\n","# Despu√©s de entrenar:\n","#   - kmeans.cluster_centers_ ‚Üí contiene las coordenadas de los centroides\n","#   - kmeans.labels_ ‚Üí etiquetas de cada punto del entrenamiento\n","\n","# ---------------------------------------------------------------\n","# üîπ Asignar clusters a los datos de validaci√≥n\n","# ---------------------------------------------------------------\n","\n","val_labels = kmeans.predict(X_val)\n","# Predice a qu√© cluster pertenece cada punto del conjunto de validaci√≥n `X_val`.\n","# val_labels ‚Üí arreglo con n√∫meros enteros [0, k_optimo-1] que representan la etiqueta de cluster asignada a cada dato.\n"],"metadata":{"id":"o_NWRiW-WHfe"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# ===============================================\n","# üìå 9. Evaluaci√≥n del modelo con Silhouette Score\n","# ==============================================="],"metadata":{"id":"I0FreBpsWMhV"}},{"cell_type":"code","source":["# ---------------------------------------------------------------\n","# üîπ Calcular el Silhouette Score para los clusters de validaci√≥n\n","# ---------------------------------------------------------------\n","\n","score_val = silhouette_score(X_val, val_labels)\n","# silhouette_score() es una funci√≥n de sklearn.metrics que mide qu√© tan bien definidos y separados est√°n los clusters.\n","#\n","# Par√°metros:\n","#   - X_val ‚Üí los datos de validaci√≥n (en este caso, normalizados/escalados)\n","#   - val_labels ‚Üí etiquetas de cluster asignadas por el modelo KMeans\n","#\n","# Concepto:\n","#   - Para cada punto, el Silhouette Score combina:\n","#       a) la distancia media entre el punto y los otros puntos del mismo cluster (cohesi√≥n)\n","#       b) la distancia media entre el punto y los puntos del cluster m√°s cercano (separaci√≥n)\n","#   - F√≥rmula simplificada:\n","#       s = (b - a) / max(a, b)\n","#       donde a = promedio de distancias dentro del mismo cluster, b = promedio de distancias al cluster m√°s cercano\n","#\n","# Interpretaci√≥n del valor:\n","#   - Rango: [-1, 1]\n","#   - s ‚âà 1 ‚Üí cluster bien definido, punto dentro de su cluster\n","#   - s ‚âà 0 ‚Üí punto entre clusters\n","#   - s < 0 ‚Üí punto mal asignado (m√°s cerca de otro cluster)\n","#   - Generalmente, un valor promedio > 0.5 indica clusters claramente separados.\n","\n","# ---------------------------------------------------------------\n","# üîπ Mostrar el resultado\n","# ---------------------------------------------------------------\n","print(f'Silhouette Score en validaci√≥n: {score_val:.2f}')\n","# Imprime el Silhouette Score en consola, redondeado a 2 decimales.\n","# Permite evaluar la calidad del clustering obtenido en los datos de validaci√≥n.\n"],"metadata":{"id":"zqrZwJs3WOQl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["| Rango del Silhouette Score | Interpretaci√≥n general               |\n","| -------------------------- | ------------------------------------ |\n","| 0.71 ‚Äì 1.00                | Clustering fuerte                    |\n","| 0.51 ‚Äì 0.70                | Clustering razonable                 |\n","| 0.26 ‚Äì 0.50                | Estructura d√©bil, pero detectable    |\n","| **0.00 ‚Äì 0.25**            | **Clustering muy d√©bil o aleatorio** |\n"],"metadata":{"id":"6x1biU3hdNM7"}},{"cell_type":"markdown","source":["# ===============================================\n","# üìå 10. Visualizaci√≥n de clusters con PCA (reducci√≥n a 2D)\n","# ==============================================="],"metadata":{"id":"-27bOmzsWQ_t"}},{"cell_type":"code","source":["# ---------------------------------------------------------------\n","# üîπ Reducci√≥n de dimensionalidad con PCA para visualizaci√≥n\n","# ---------------------------------------------------------------\n","\n","pca = PCA(n_components=2)\n","# Creamos un objeto PCA (Principal Component Analysis) para reducir la dimensionalidad de los datos.\n","# n_components=2 ‚Üí queremos reducir los datos a 2 dimensiones, para poder graficarlos en un plano XY.\n","# PCA transforma los datos originales en nuevas variables ortogonales llamadas \"componentes principales\",\n","# que capturan la mayor varianza posible de los datos.\n","\n","X_val_pca = pca.fit_transform(X_val)\n","# fit_transform() realiza dos pasos:\n","#   1. fit() ‚Üí calcula los componentes principales a partir de los datos X_val.\n","#   2. transform() ‚Üí proyecta los datos originales sobre estos componentes principales.\n","# Resultado: `X_val_pca` es un array de 2 columnas (PC1 y PC2) con los datos proyectados,\n","# listo para visualizaci√≥n en 2D.\n","\n","# ---------------------------------------------------------------\n","# üîπ Predecir clusters finales para todo el DataFrame escalado\n","# ---------------------------------------------------------------\n","\n","cluster_labels = kmeans.predict(df_scaled)\n","# Usamos el modelo KMeans ya entrenado para asignar un cluster a cada punto de `df_scaled`.\n","# Resultado: un array de etiquetas [0, k_optimo-1] que indica a qu√© cluster pertenece cada dato.\n","\n","# ---------------------------------------------------------------\n","# üîπ Agregar los resultados de clustering al DataFrame original\n","# ---------------------------------------------------------------\n","\n","df_clean['Cluster'] = cluster_labels\n","# Creamos una nueva columna 'Cluster' en `df_clean` que almacena la etiqueta de cluster de cada registro.\n","# Esto permite:\n","#   - Analizar estad√≠sticas por cluster\n","#   - Visualizar clusters con gr√°ficos\n","#   - Combinar con otras variables categ√≥ricas o num√©ricas\n"],"metadata":{"id":"GufqUDGjWSoV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ==============================================================\n","# üè∑Ô∏è ETIQUETADO DE SEGMENTOS SEG√öN PERFIL\n","# ==============================================================\n","\n","# ---------------------------------------------------------------\n","# üîπ Analizar caracter√≠sticas promedio por cluster\n","# ---------------------------------------------------------------\n","\n","cluster_summary = df_clean.groupby('Cluster').mean(numeric_only=True)\n","# df_clean.groupby('Cluster') ‚Üí agrupa los datos por la columna 'Cluster'.\n","# .mean(numeric_only=True) ‚Üí calcula la media de las variables num√©ricas para cada cluster.\n","#\n","# Resultado:\n","#   - Un DataFrame donde cada fila representa un cluster\n","#   - Cada columna muestra la media de esa variable dentro del cluster\n","#   - Permite identificar patrones: edad promedio, ingreso promedio, gasto promedio, etc.\n","\n","display(cluster_summary)\n","# Muestra el resumen de manera visual (especialmente √∫til en Jupyter Notebook o entornos interactivos)\n","# para poder inspeccionar r√°pidamente los perfiles de cada cluster.\n","\n","# ---------------------------------------------------------------\n","# üîπ Asignar etiquetas descriptivas a los clusters\n","# ---------------------------------------------------------------\n","\n","nombres_segmentos = {\n","    0: \"Clientes conservadores\",\n","    1: \"Compradores impulsivos\",\n","    2: \"Clientes premium activos\",\n","    3: \"Clientes cautelosos\",\n","    4: \"Potencial no explotado\"\n","}\n","# Creamos un diccionario que asigna un nombre descriptivo a cada cluster.\n","# Claves ‚Üí n√∫mero del cluster (0,1,2,3,4)\n","# Valores ‚Üí nombre del segmento basado en an√°lisis de medias y comportamiento del cliente\n","\n","df_clean['Segmento'] = df_clean['Cluster'].map(nombres_segmentos)\n","# Usamos .map() para reemplazar cada etiqueta num√©rica de cluster con su nombre descriptivo.\n","# Resultado:\n","#   - Nueva columna 'Segmento' en df_clean\n","#   - Permite trabajar con etiquetas comprensibles y no solo n√∫meros\n","#   - Facilita an√°lisis y visualizaci√≥n de perfiles de clientes\n"],"metadata":{"id":"RxkUqVzihwTY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ==============================================================\n","# üß† AN√ÅLISIS DE NEGOCIO\n","# ==============================================================\n","\n","# ---------------------------------------------------------------\n","# üîπ Conteo de clientes por segmento\n","# ---------------------------------------------------------------\n","\n","conteo_segmentos = df_clean['Segmento'].value_counts()\n","# df_clean['Segmento'] ‚Üí accede a la columna que contiene las etiquetas descriptivas de cada cluster.\n","# .value_counts() ‚Üí cuenta cu√°ntas veces aparece cada etiqueta en la columna.\n","#\n","# Resultado:\n","#   - Un objeto pandas Series donde:\n","#       - √≠ndice ‚Üí nombre del segmento\n","#       - valor ‚Üí n√∫mero de clientes en ese segmento\n","#   - Permite conocer la distribuci√≥n de clientes entre los distintos perfiles identificados.\n","\n","# ---------------------------------------------------------------\n","# üîπ Mostrar resultados en consola\n","# ---------------------------------------------------------------\n","print(\"Distribuci√≥n de clientes por segmento:\\n\")\n","print(conteo_segmentos)\n","# Imprime en pantalla la cantidad de clientes en cada segmento\n","# √ötil para identificar:\n","#   - Segmentos m√°s grandes o dominantes\n","#   - Segmentos peque√±os o nichos\n","#   - Potencial de enfoque de marketing o estrategia de negocio\n"],"metadata":{"id":"GH7-TY1JjMzP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# ===============================================\n","# üìå 11. Validaci√≥n final en el conjunto de prueba\n","# ==============================================="],"metadata":{"id":"Mh5LsXK2WZFl"}},{"cell_type":"code","source":["# ---------------------------------------------------------------\n","# üîπ Aplicar el modelo KMeans entrenado al conjunto de prueba\n","# ---------------------------------------------------------------\n","\n","test_labels = kmeans.predict(X_test)\n","# predict() asigna cada punto del conjunto de prueba X_test a un cluster seg√∫n los centroides encontrados\n","# durante el entrenamiento con X_train.\n","# Resultado:\n","#   - test_labels ‚Üí array con las etiquetas de cluster para cada punto del test set\n","#   - Etiquetas en el rango [0, k_optimo-1]\n","\n","# ---------------------------------------------------------------\n","# üîπ Calcular el Silhouette Score en los datos de prueba\n","# ---------------------------------------------------------------\n","\n","score_test = silhouette_score(X_test, test_labels)\n","# silhouette_score() mide qu√© tan bien separados y definidos est√°n los clusters\n","# para los datos de prueba.\n","#\n","# Par√°metros:\n","#   - X_test ‚Üí datos del conjunto de prueba\n","#   - test_labels ‚Üí etiquetas de cluster asignadas\n","#\n","# Interpretaci√≥n:\n","#   - Valor entre -1 y 1\n","#   - >0.5 ‚Üí clusters bien definidos\n","#   - ~0 ‚Üí clusters poco definidos, puntos cerca de l√≠mites de cluster\n","#   - <0 ‚Üí clusters mal asignados\n","\n","# ---------------------------------------------------------------\n","# üîπ Mostrar resultado\n","# ---------------------------------------------------------------\n","print(f'Silhouette Score en test: {score_test:.2f}')\n","# Imprime en consola el Silhouette Score redondeado a 2 decimales\n","# Permite evaluar si el modelo generaliza bien y si los clusters siguen siendo consistentes en nuevos datos\n"],"metadata":{"id":"RNhl9h_KWa7-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##Exportar resultados a Excel"],"metadata":{"id":"yqOHYgJckkFg"}},{"cell_type":"code","source":["# Exportamos el dataframe con segmentos a Excel (requiere openpyxl instalado)\n","df_clean.to_excel('/content/Clientes_Segmentados.xlsx', index=False)\n","\n","print(\"‚úÖ Archivo exportado como Clientes_Segmentados.xlsx\")\n"],"metadata":{"id":"PKQYwuaGknIQ"},"execution_count":null,"outputs":[]}]}